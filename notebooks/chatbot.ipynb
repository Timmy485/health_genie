{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ObJyme2Px4p2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    load_index_from_storage,\n",
        "    StorageContext,\n",
        ")\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from os import environ\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dupETSpzjZ9"
      },
      "source": [
        "### Set Up Api Key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = environ.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76x5H10vywdv"
      },
      "source": [
        "### Load Data Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('data/paul_graham/paul_graham_essay.txt',\n",
              " <http.client.HTTPMessage at 0x1a2ddd72110>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs('data/paul_graham/', exist_ok=True)\n",
        "\n",
        "# Download file\n",
        "url = 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt'\n",
        "file_path = 'data/paul_graham/paul_graham_essay.txt'\n",
        "urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(input_dir=\"./data/paul_graham/\").load_data()\n",
        "# check if storage already exists\n",
        "PERSIST_DIR = \"./storage\"\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # store it for later\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "  # rebuild storage context\n",
        "  storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
        "  # load index\n",
        "  index = load_index_from_storage(storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=5000)\n",
        "\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"context\",\n",
        "    memory=memory,\n",
        "    system_prompt=(\n",
        "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
        "        \" about an essay discussing Paul Grahams life.\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How are you doing today?\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat(\"Hello!\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Growing up, Paul Graham was interested in writing and programming. He wrote short stories and also started programming on the IBM 1401 computer that his school district used for data processing when he was in 9th grade. Later, he got a microcomputer and started writing simple games, programs, and even a word processor. Despite his initial interest in philosophy, he eventually switched to studying AI in college due to his fascination with intelligent computers portrayed in literature and documentaries.\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat(\"What did Paul Graham do growing up?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
